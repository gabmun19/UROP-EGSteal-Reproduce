{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 --force-reinstall\n",
        "import numpy as np\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "collapsed": true,
        "id": "qHV5nbrzgv1l",
        "outputId": "39c57411-5112-4349-b6fe-287f8e8d6e11"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "1a01c0bbaa1d4065aa0c0994230cb113"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cYCADltpglul",
        "outputId": "2d9f45d0-47d9-4cea-a7b9-c733e4ed7464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.9.0+cu126\n",
            "Uninstalling torch-2.9.0+cu126:\n",
            "  Successfully uninstalled torch-2.9.0+cu126\n",
            "\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torchvision 0.24.0+cu126\n",
            "Uninstalling torchvision-0.24.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.24.0+cu126\n",
            "Found existing installation: torchaudio 2.9.0+cu126\n",
            "Uninstalling torchaudio-2.9.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "Collecting torch==2.2.0\n",
            "  Downloading torch-2.2.0-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchvision==0.17.0\n",
            "  Downloading torchvision-0.17.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting torchaudio==2.2.0\n",
            "  Downloading torchaudio-2.2.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.0)\n",
            "  Downloading triton-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.17.0) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchvision==0.17.0) (2.32.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.17.0) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.2.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchvision==0.17.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchvision==0.17.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchvision==0.17.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchvision==0.17.0) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.0) (1.3.0)\n",
            "Downloading torch-2.2.0-cp312-cp312-manylinux1_x86_64.whl (755.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.4/755.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.0-cp312-cp312-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.2.0-cp312-cp312-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 torchaudio-2.2.0 torchvision-0.17.0 triton-2.2.0\n",
            "Collecting torch-geometric==2.4.0\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-scatter==2.1.1\n",
            "  Downloading torch_scatter-2.1.1.tar.gz (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse==0.6.18\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-cluster==1.6.3\n",
            "  Downloading torch_cluster-1.6.3.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric==2.4.0) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-geometric==2.4.0) (1.16.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric==2.4.0) (2.32.4)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric==2.4.0) (3.2.5)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric==2.4.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric==2.4.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric==2.4.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric==2.4.0) (2025.11.12)\n",
            "Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch-scatter, torch-sparse, torch-cluster\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.1-cp312-cp312-linux_x86_64.whl size=504084 sha256=b9caae8035a894af0fa52a8447d599f192f07e75f4f95a64c4347cb93550a2b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/d1/b1/797fc1b4de71a2d7f811dd0c5223fcdfe22bfdc95a5ecb6d21\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp312-cp312-linux_x86_64.whl size=1092344 sha256=6fe9f734c58e6e66259cd08159496864af10271a8e07dcf90264bda423a4077c\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/fa/21/bd1d78ce1629aec4ecc924a63b82f6949dda484b6321eac6f2\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.6.3-cp312-cp312-linux_x86_64.whl size=727924 sha256=cc2c5b2fcc9e669a1647937e7476243abc9c79402fa17d96bab63931a3a409da\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/8f/d0/13408a84825c9a587151a74727b4a6d47ec67e0d625b385ad7\n",
            "Successfully built torch-scatter torch-sparse torch-cluster\n",
            "Installing collected packages: torch-scatter, torch-sparse, torch-cluster, torch-geometric\n",
            "Successfully installed torch-cluster-1.6.3 torch-geometric-2.4.0 torch-scatter-2.1.1 torch-sparse-0.6.18\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y torch torch-geometric torch-scatter torch-sparse torch-cluster torchvision torchaudio\n",
        "!pip install torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0\n",
        "!pip install torch-geometric==2.4.0 torch-scatter==2.1.1 torch-sparse==0.6.18 torch-cluster==1.6.3 tqdm scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone EGSteal repository\n",
        "!git clone https://github.com/beanmah/EGSteal.git\n",
        "%cd EGSteal\n",
        "!ls"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btjbJV-WqAu1",
        "outputId": "ad4e6e70-f1d9-4c4b-fdfa-be661176b730"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EGSteal'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 25 (delta 1), reused 21 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (25/25), 294.54 KiB | 9.50 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "/content/EGSteal\n",
            "data_preparation.py\t\tsample_query_dataset.py\n",
            "generate_experiment_setting.py\tsplitters.py\n",
            "LICENSE\t\t\t\ttarget_model_inference.py\n",
            "loader.py\t\t\ttarget_model_inference_w_pretrain.py\n",
            "model.py\t\t\ttrain_surrogate_model_for_target_w_pretrain.py\n",
            "model_w_pretrain.py\t\ttrain_surrogate_model.py\n",
            "pipeline.png\t\t\ttrain_target_model.py\n",
            "README.md\t\t\ttrain_target_model_w_pretrain.py\n",
            "requirements.txt\t\tutils.py\n",
            "run_experiments.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ziDdmbUSkJK"
      },
      "source": [
        "NCI109 dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preapre NCI109 Dataset\n",
        "!mkdir -p dataset/NCI109/raw\n",
        "!wget -q https://www.chrsmrrs.com/graphkerneldatasets/NCI109.zip -O dataset/NCI109/raw/NCI109.zip\n",
        "!unzip -o dataset/NCI109/raw/NCI109.zip -d dataset/NCI109/raw/\n",
        "\n",
        "# Convert TU dataset to PyG .pt splits\n",
        "!python data_preparation.py --dataset_name NCI109"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKBGjwNgqJAg",
        "outputId": "5f219193-8865-482c-c872-df07c56a517b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset/NCI109/raw/NCI109.zip\n",
            "   creating: dataset/NCI109/raw/NCI109/\n",
            "  inflating: dataset/NCI109/raw/NCI109/NCI109_graph_indicator.txt  \n",
            "  inflating: dataset/NCI109/raw/NCI109/NCI109_graph_labels.txt  \n",
            "  inflating: dataset/NCI109/raw/NCI109/NCI109_A.txt  \n",
            "  inflating: dataset/NCI109/raw/NCI109/README.txt  \n",
            "  inflating: dataset/NCI109/raw/NCI109/NCI109_node_labels.txt  \n",
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/NCI109.zip\n",
            "Extracting dataset/NCI109/NCI109.zip\n",
            "Processing...\n",
            "Done!\n",
            "\n",
            "Total number of graphs in NCI109: 4127\n",
            "Node features dimension: 38\n",
            "Edge features dimension: 0\n",
            "Number of classes: 2\n",
            "\n",
            "Dataset split sizes:\n",
            "Target train set size: 1320 (32.0%)\n",
            "Target val set size: 330 (8.0%)\n",
            "Test set size: 825 (20.0%)\n",
            "Shadow dataset size: 1652 (40.0%)\n",
            "\n",
            "Datasets saved in dataset/NCI109/processed_splits\n",
            "Saved files:\n",
            "- dataset_info.pt\n",
            "- target_train_dataset.pt\n",
            "- target_val_dataset.pt\n",
            "- test_dataset.pt\n",
            "- shadow_dataset.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5-PN6dxSb6u",
        "outputId": "d4a15679-d56f-4c39-b7c0-df5d01cbabae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "Number of node features: 38\n",
            "Number of classes: 2\n",
            "Target training dataset size: 1320\n",
            "Target validation dataset size: 330\n",
            "Test dataset size: 825\n",
            "Epochs: 100% 200/200 [03:27<00:00,  1.04s/it, Train Loss=0.0317, Train Acc=0.9939, Train AUC=0.9997, Val Loss=1.5768, Val Acc=0.7303, Val AUC=0.7880]\n",
            "\n",
            "Best Target GNN model saved to model_weights/NCI109/target_gnn_model.pth with Val AUC: 0.8132\n",
            "Test Accuracy of the best model: 0.7321\n",
            "Test AUC of the best model: 0.8013\n",
            "Best test accuracy and AUC saved to model_weights/NCI109/target_results.pt\n"
          ]
        }
      ],
      "source": [
        "# Train the target model (this is the original model being stolen)\n",
        "!python train_target_model.py --dataset_name NCI109 --gnn_backbone GIN --gnn_layer 3 --gnn_hidden_dim 128 --epochs 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z1EtP2SSdRS",
        "outputId": "168d0684-c32a-4b8a-e573-bf265fe7ae15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Target GNN model.\n",
            "\n",
            "Processing shadow_dataset.pt...\n",
            "Dataset Size: 1652\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "Processed 1024/1652 graphs.\n",
            "Processed 1652/1652 graphs.\n",
            "Saved processed dataset to dataset/NCI109/processed_splits/queried_dataset_shadow.pt\n",
            "\n",
            "Processing test_dataset.pt...\n",
            "Dataset Size: 825\n",
            "Processed 825/825 graphs.\n",
            "Saved processed dataset to dataset/NCI109/processed_splits/queried_dataset_test.pt\n"
          ]
        }
      ],
      "source": [
        "# Run CAM explanations to obtain graph-level importance maps\n",
        "!python target_model_inference.py --dataset_name NCI109 --explanation_mode CAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNfOw46MSefJ",
        "outputId": "c5f5addb-e3fb-459c-a738-4913936e85e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total number of graphs in queried_dataset_shadow: 1652\n",
            "Total samples: 495\n",
            "Number of sampled samples: 495\n",
            "\n",
            "Training set:\n",
            "Total training samples: 396\n",
            "\n",
            "Validation set:\n",
            "Total validation samples: 99\n",
            "\n",
            "Query dataset split saved:\n",
            "- Training set (396 samples) saved to: dataset/NCI109/processed_splits/queried_dataset_train.pt\n",
            "- Validation set (99 samples) saved to: dataset/NCI109/processed_splits/queried_dataset_val.pt\n",
            "Total query dataset size: 495\n",
            "Split ratio (train/val): 0.8/0.19999999999999996\n"
          ]
        }
      ],
      "source": [
        "# Use the sampler to generate query sets\n",
        "!python sample_query_dataset.py --dataset_name NCI109"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDWla9ttSf2J",
        "outputId": "b06e9813-e9f2-46d0-d26f-ab1670110ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset Size: 396\n",
            "Val Dataset Size: 99\n",
            "Test Dataset Size: 825\n",
            "Starting training...\n",
            "Training: 100% 200/200 [02:19<00:00,  1.44it/s, Train Pred Loss=0.0523, Train RankNet Loss=0.5587, Val Acc=0.6869, Val AUC=0.7208]\n",
            "\n",
            "Best Validation AUC: 0.8187\n",
            "Test Accuracy: 0.6836\n",
            "Test AUC: 0.7529\n",
            "Fidelity Score: 0.7406\n",
            "Order Accuracy: 0.6089\n",
            "Rank Correlation: 0.1983\n",
            "Results saved to model_weights/NCI109/surrogate_results.pt\n"
          ]
        }
      ],
      "source": [
        "# Train the surrogate model using:\n",
        "# sampled queries, augmentation, alignmnet loss\n",
        "!python train_surrogate_model.py --dataset_name NCI109 --align_weight 0.1 --augmentation_ratio 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AIDS Dataset"
      ],
      "metadata": {
        "id": "FKU90nHeqfO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preapre AIDS Dataset\n",
        "!mkdir -p dataset/AIDS/raw\n",
        "!wget -q https://www.chrsmrrs.com/graphkerneldatasets/AIDS.zip -O dataset/AIDS/raw/AIDS.zip\n",
        "!unzip -o dataset/AIDS/raw/AIDS.zip -d dataset/AIDS/raw/\n",
        "\n",
        "# Convert TU dataset to PyG .pt splits\n",
        "!python data_preparation.py --dataset_name AIDS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFwPShvyqhme",
        "outputId": "37411b72-3863-4a79-e11a-324eb604e94b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset/AIDS/raw/AIDS.zip\n",
            "   creating: dataset/AIDS/raw/AIDS/\n",
            "  inflating: dataset/AIDS/raw/AIDS/AIDS_graph_labels.txt  \n",
            "  inflating: dataset/AIDS/raw/AIDS/AIDS_node_attributes.txt  \n",
            "  inflating: dataset/AIDS/raw/AIDS/AIDS_graph_indicator.txt  \n",
            "  inflating: dataset/AIDS/raw/AIDS/AIDS_node_labels.txt  \n",
            "  inflating: dataset/AIDS/raw/AIDS/AIDS_edge_labels.txt  \n",
            "  inflating: dataset/AIDS/raw/AIDS/AIDS_label_readme.txt  \n",
            "  inflating: dataset/AIDS/raw/AIDS/AIDS_A.txt  \n",
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/AIDS.zip\n",
            "Extracting dataset/AIDS/AIDS.zip\n",
            "Processing...\n",
            "Done!\n",
            "\n",
            "Total number of graphs in AIDS: 2000\n",
            "Node features dimension: 38\n",
            "Edge features dimension: 3\n",
            "Number of classes: 2\n",
            "\n",
            "Dataset split sizes:\n",
            "Target train set size: 640 (32.0%)\n",
            "Target val set size: 160 (8.0%)\n",
            "Test set size: 400 (20.0%)\n",
            "Shadow dataset size: 800 (40.0%)\n",
            "\n",
            "Datasets saved in dataset/AIDS/processed_splits\n",
            "Saved files:\n",
            "- dataset_info.pt\n",
            "- target_train_dataset.pt\n",
            "- target_val_dataset.pt\n",
            "- test_dataset.pt\n",
            "- shadow_dataset.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the target model (this is the original model being stolen)\n",
        "!python train_target_model.py --dataset_name AIDS --gnn_backbone GIN --gnn_layer 3 --gnn_hidden_dim 128 --epochs 200"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kAJsWTXqjh5",
        "outputId": "a7d3954a-86bc-46b3-af34-2869e6773268"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "Number of node features: 38\n",
            "Number of classes: 2\n",
            "Target training dataset size: 640\n",
            "Target validation dataset size: 160\n",
            "Test dataset size: 400\n",
            "Epochs: 100% 200/200 [01:09<00:00,  2.87it/s, Train Loss=0.0257, Train Acc=0.9938, Train AUC=0.9996, Val Loss=0.3926, Val Acc=0.9000, Val AUC=0.9717]\n",
            "\n",
            "Best Target GNN model saved to model_weights/AIDS/target_gnn_model.pth with Val AUC: 0.9905\n",
            "Test Accuracy of the best model: 0.9075\n",
            "Test AUC of the best model: 0.9574\n",
            "Best test accuracy and AUC saved to model_weights/AIDS/target_results.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run CAM explanations to obtain graph-level importance maps\n",
        "!python target_model_inference.py --dataset_name AIDS --explanation_mode CAM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF8D78B3qlae",
        "outputId": "82d9b723-71d5-4fda-fcc3-8685a2d36691"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Target GNN model.\n",
            "\n",
            "Processing shadow_dataset.pt...\n",
            "Dataset Size: 800\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "Processed 800/800 graphs.\n",
            "Saved processed dataset to dataset/AIDS/processed_splits/queried_dataset_shadow.pt\n",
            "\n",
            "Processing test_dataset.pt...\n",
            "Dataset Size: 400\n",
            "Processed 400/400 graphs.\n",
            "Saved processed dataset to dataset/AIDS/processed_splits/queried_dataset_test.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the sampler to generate query sets\n",
        "!python sample_query_dataset.py --dataset_name AIDS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEYAjnsvqnRe",
        "outputId": "d6b15ea1-cbfd-4939-8b8c-d1f061ccfc67"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total number of graphs in queried_dataset_shadow: 800\n",
            "Total samples: 240\n",
            "Number of sampled samples: 240\n",
            "\n",
            "Training set:\n",
            "Total training samples: 192\n",
            "\n",
            "Validation set:\n",
            "Total validation samples: 48\n",
            "\n",
            "Query dataset split saved:\n",
            "- Training set (192 samples) saved to: dataset/AIDS/processed_splits/queried_dataset_train.pt\n",
            "- Validation set (48 samples) saved to: dataset/AIDS/processed_splits/queried_dataset_val.pt\n",
            "Total query dataset size: 240\n",
            "Split ratio (train/val): 0.8/0.19999999999999996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the surrogate model using:\n",
        "# sampled queries, augmentation, alignmnet loss\n",
        "!python train_surrogate_model.py --dataset_name AIDS --align_weight 0.1 --augmentation_ratio 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaQXSFoiqqAu",
        "outputId": "fcea114a-f85d-403c-d8b1-cf6c0c36c4a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset Size: 192\n",
            "Val Dataset Size: 48\n",
            "Test Dataset Size: 400\n",
            "Starting training...\n",
            "Training: 100% 200/200 [00:50<00:00,  3.98it/s, Train Pred Loss=0.0367, Train RankNet Loss=0.5018, Val Acc=0.8958, Val AUC=0.9631]\n",
            "\n",
            "Best Validation AUC: 1.0000\n",
            "Test Accuracy: 0.8400\n",
            "Test AUC: 0.9073\n",
            "Fidelity Score: 0.8775\n",
            "Order Accuracy: 0.7031\n",
            "Rank Correlation: 0.3850\n",
            "Results saved to model_weights/AIDS/surrogate_results.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjNnn1pNv1pm"
      },
      "source": [
        "Mutagenicity Datset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAir6HPEv9Bb",
        "outputId": "a4841701-f83d-4056-8ba9-0d31ebee7e17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset/MUTAG/raw/MUTAG.zip\n",
            "   creating: dataset/MUTAG/raw/MUTAG/\n",
            "  inflating: dataset/MUTAG/raw/MUTAG/MUTAG_graph_labels.txt  \n",
            "  inflating: dataset/MUTAG/raw/MUTAG/MUTAG_node_labels.txt  \n",
            "  inflating: dataset/MUTAG/raw/MUTAG/MUTAG_graph_indicator.txt  \n",
            "  inflating: dataset/MUTAG/raw/MUTAG/MUTAG_A.txt  \n",
            "  inflating: dataset/MUTAG/raw/MUTAG/MUTAG_edge_labels.txt  \n",
            "  inflating: dataset/MUTAG/raw/MUTAG/README.txt  \n",
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/Mutagenicity.zip\n",
            "Extracting dataset/Mutagenicity/Mutagenicity.zip\n",
            "Processing...\n",
            "Done!\n",
            "\n",
            "Total number of graphs in Mutagenicity: 4337\n",
            "Node features dimension: 14\n",
            "Edge features dimension: 3\n",
            "Number of classes: 2\n",
            "\n",
            "Dataset split sizes:\n",
            "Target train set size: 1387 (32.0%)\n",
            "Target val set size: 347 (8.0%)\n",
            "Test set size: 867 (20.0%)\n",
            "Shadow dataset size: 1736 (40.0%)\n",
            "\n",
            "Datasets saved in dataset/Mutagenicity/processed_splits\n",
            "Saved files:\n",
            "- dataset_info.pt\n",
            "- target_train_dataset.pt\n",
            "- target_val_dataset.pt\n",
            "- test_dataset.pt\n",
            "- shadow_dataset.pt\n"
          ]
        }
      ],
      "source": [
        "# Preapre AIDS Dataset\n",
        "!mkdir -p dataset/MUTAG/raw\n",
        "!wget -q https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip -O dataset/MUTAG/raw/MUTAG.zip\n",
        "!unzip -o dataset/MUTAG/raw/MUTAG.zip -d dataset/MUTAG/raw/\n",
        "\n",
        "# Convert TU dataset to PyG .pt splits\n",
        "!python data_preparation.py --dataset_name Mutagenicity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN7PqHldwJxG",
        "outputId": "2fa017fb-5ba8-48f5-c113-2da0d2214c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "Number of node features: 14\n",
            "Number of classes: 2\n",
            "Target training dataset size: 1387\n",
            "Target validation dataset size: 347\n",
            "Test dataset size: 867\n",
            "Epochs: 100% 200/200 [03:23<00:00,  1.02s/it, Train Loss=0.1214, Train Acc=0.9560, Train AUC=0.9908, Val Loss=1.3691, Val Acc=0.7723, Val AUC=0.8065]\n",
            "\n",
            "Best Target GNN model saved to model_weights/Mutagenicity/target_gnn_model.pth with Val AUC: 0.8222\n",
            "Test Accuracy of the best model: 0.7889\n",
            "Test AUC of the best model: 0.8409\n",
            "Best test accuracy and AUC saved to model_weights/Mutagenicity/target_results.pt\n"
          ]
        }
      ],
      "source": [
        "# Train the target model (this is the original model being stolen)\n",
        "!python train_target_model.py --dataset_name Mutagenicity --gnn_backbone GIN --gnn_layer 3 --gnn_hidden_dim 128 --epochs 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgIJaS_rwPPj",
        "outputId": "b42c7257-9b3b-46d2-c7b5-f0760ddadb77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Target GNN model.\n",
            "\n",
            "Processing shadow_dataset.pt...\n",
            "Dataset Size: 1736\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "Processed 1024/1736 graphs.\n",
            "Processed 1736/1736 graphs.\n",
            "Saved processed dataset to dataset/Mutagenicity/processed_splits/queried_dataset_shadow.pt\n",
            "\n",
            "Processing test_dataset.pt...\n",
            "Dataset Size: 867\n",
            "Processed 867/867 graphs.\n",
            "Saved processed dataset to dataset/Mutagenicity/processed_splits/queried_dataset_test.pt\n"
          ]
        }
      ],
      "source": [
        "# Run CAM explanations to obtain graph-level importance maps\n",
        "!python target_model_inference.py --dataset_name Mutagenicity --explanation_mode CAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1GHZ1tGwTL7",
        "outputId": "66f43790-6d79-4906-8219-cc13392b7fcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total number of graphs in queried_dataset_shadow: 1736\n",
            "Total samples: 520\n",
            "Number of sampled samples: 520\n",
            "\n",
            "Training set:\n",
            "Total training samples: 416\n",
            "\n",
            "Validation set:\n",
            "Total validation samples: 104\n",
            "\n",
            "Query dataset split saved:\n",
            "- Training set (416 samples) saved to: dataset/Mutagenicity/processed_splits/queried_dataset_train.pt\n",
            "- Validation set (104 samples) saved to: dataset/Mutagenicity/processed_splits/queried_dataset_val.pt\n",
            "Total query dataset size: 520\n",
            "Split ratio (train/val): 0.8/0.19999999999999996\n"
          ]
        }
      ],
      "source": [
        "# Use the sampler to generate query sets\n",
        "!python sample_query_dataset.py --dataset_name Mutagenicity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GojmzeVLwURs",
        "outputId": "838fbc5f-b7ff-43e8-b4c4-a8368b85cd11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset Size: 416\n",
            "Val Dataset Size: 104\n",
            "Test Dataset Size: 867\n",
            "Starting training...\n",
            "Training: 100% 200/200 [02:30<00:00,  1.33it/s, Train Pred Loss=0.0566, Train RankNet Loss=0.5096, Val Acc=0.7788, Val AUC=0.8550]\n",
            "\n",
            "Best Validation AUC: 0.8881\n",
            "Test Accuracy: 0.7589\n",
            "Test AUC: 0.8075\n",
            "Fidelity Score: 0.8131\n",
            "Order Accuracy: 0.6912\n",
            "Rank Correlation: 0.3472\n",
            "Results saved to model_weights/Mutagenicity/surrogate_results.pt\n"
          ]
        }
      ],
      "source": [
        "# Train the surrogate model using:\n",
        "# sampled queries, augmentation, alignmnet loss\n",
        "!python train_surrogate_model.py --dataset_name Mutagenicity --align_weight 0.1 --augmentation_ratio 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jyFoWfW0WXh"
      },
      "source": [
        "Download results from every Dataset (NCI109, AIDS, Mutagenicity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lloPjHJv0fUt",
        "outputId": "afb7fc37-451b-49b1-d74b-4cd738ee92ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: results\n",
            "  adding: model_weights/NCI109/ (stored 0%)\n",
            "  adding: model_weights/NCI109/target_gnn_model.pth (deflated 9%)\n",
            "  adding: model_weights/NCI109/surrogate_results.pt (deflated 51%)\n",
            "  adding: model_weights/NCI109/target_results.pt (deflated 54%)\n",
            "  adding: model_weights/AIDS/ (stored 0%)\n",
            "  adding: model_weights/AIDS/target_gnn_model.pth (deflated 10%)\n",
            "  adding: model_weights/AIDS/surrogate_results.pt (deflated 51%)\n",
            "  adding: model_weights/AIDS/target_results.pt (deflated 54%)\n",
            "  adding: model_weights/Mutagenicity/ (stored 0%)\n",
            "  adding: model_weights/Mutagenicity/target_gnn_model.pth (deflated 9%)\n",
            "  adding: model_weights/Mutagenicity/surrogate_results.pt (deflated 52%)\n",
            "  adding: model_weights/Mutagenicity/target_results.pt (deflated 55%)\n",
            "  adding: dataset/NCI109/processed_splits/ (stored 0%)\n",
            "  adding: dataset/NCI109/processed_splits/target_train_dataset.pt (deflated 98%)\n",
            "  adding: dataset/NCI109/processed_splits/test_dataset.pt (deflated 98%)\n",
            "  adding: dataset/NCI109/processed_splits/shadow_dataset.pt (deflated 98%)\n",
            "  adding: dataset/NCI109/processed_splits/queried_dataset_shadow.pt (deflated 93%)\n",
            "  adding: dataset/NCI109/processed_splits/queried_dataset_test.pt (deflated 93%)\n",
            "  adding: dataset/NCI109/processed_splits/dataset_info.pt (deflated 55%)\n",
            "  adding: dataset/NCI109/processed_splits/queried_dataset_val.pt (deflated 93%)\n",
            "  adding: dataset/NCI109/processed_splits/queried_dataset_train.pt (deflated 93%)\n",
            "  adding: dataset/NCI109/processed_splits/target_val_dataset.pt (deflated 98%)\n",
            "  adding: dataset/AIDS/processed_splits/ (stored 0%)\n",
            "  adding: dataset/AIDS/processed_splits/target_train_dataset.pt (deflated 95%)\n",
            "  adding: dataset/AIDS/processed_splits/test_dataset.pt (deflated 95%)\n",
            "  adding: dataset/AIDS/processed_splits/shadow_dataset.pt (deflated 95%)\n",
            "  adding: dataset/AIDS/processed_splits/queried_dataset_shadow.pt (deflated 92%)\n",
            "  adding: dataset/AIDS/processed_splits/queried_dataset_test.pt (deflated 92%)\n",
            "  adding: dataset/AIDS/processed_splits/dataset_info.pt (deflated 55%)\n",
            "  adding: dataset/AIDS/processed_splits/queried_dataset_val.pt (deflated 92%)\n",
            "  adding: dataset/AIDS/processed_splits/queried_dataset_train.pt (deflated 92%)\n",
            "  adding: dataset/AIDS/processed_splits/target_val_dataset.pt (deflated 95%)\n",
            "  adding: dataset/Mutagenicity/processed_splits/ (stored 0%)\n",
            "  adding: dataset/Mutagenicity/processed_splits/target_train_dataset.pt (deflated 97%)\n",
            "  adding: dataset/Mutagenicity/processed_splits/test_dataset.pt (deflated 97%)\n",
            "  adding: dataset/Mutagenicity/processed_splits/shadow_dataset.pt (deflated 97%)\n",
            "  adding: dataset/Mutagenicity/processed_splits/queried_dataset_shadow.pt (deflated 91%)\n",
            "  adding: dataset/Mutagenicity/processed_splits/queried_dataset_test.pt (deflated 91%)\n",
            "  adding: dataset/Mutagenicity/processed_splits/dataset_info.pt (deflated 55%)\n",
            "  adding: dataset/Mutagenicity/processed_splits/queried_dataset_val.pt (deflated 91%)\n",
            "  adding: dataset/Mutagenicity/processed_splits/queried_dataset_train.pt (deflated 91%)\n",
            "  adding: dataset/Mutagenicity/processed_splits/target_val_dataset.pt (deflated 97%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r week7_results.zip \\\n",
        "results \\\n",
        "model_weights/NCI109 \\\n",
        "model_weights/AIDS \\\n",
        "model_weights/Mutagenicity \\\n",
        "dataset/NCI109/processed_splits \\\n",
        "dataset/AIDS/processed_splits \\\n",
        "dataset/Mutagenicity/processed_splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "by4AUKWD08z-",
        "outputId": "59c9f019-3da4-4b1a-a92a-90390df3ceb9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e94ebd0a-68c1-4146-89c8-7e0147fea1b4\", \"week7_results.zip\", 13378641)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"week7_results.zip\")"
      ]
    }
  ]
}